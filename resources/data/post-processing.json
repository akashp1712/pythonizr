{
  "name": "Evaluation",
  "data": {
    "mae": {
      "name": "Mean Absolute Error",
      "imports": ["from sklearn.metrics import mean_absolute_error"],
      "code": [
        "# Make predictions using the testing set",
        "y_predict = reg.predict(X_test)",
        "mae = mean_absolute_error(y_test, y_predict)"
      ]
    },
    "mse": {
      "name": "Mean Squared Error",
      "imports": ["from sklearn.metrics import mean_squared_error"],
      "code": [
        "# Make predictions using the testing set",
        "y_predict = reg.predict(X_test)",
        "mse = mean_squared_error(y_test, y_predict)"
      ]
    },
    "r2Score": {
      "name": "RÂ² Score",
      "imports": ["from sklearn.metrics import r2_score"],
      "code": [
        "# Make predictions using the testing set",
        "y_predict = reg.predict(X_test)",
        "r2score = r2_score(y_true, y_predict)"
      ]
    },
    "accuracyScore": {
      "name": "Accuracy Score",
      "imports": ["from sklearn.metrics import accuracy_score"],
      "code": [
        "# Make predictions using the testing set",
        "y_predict = clf.predict(X_test)",
        "accuracy = accuracy_score(y_test, y_pred)"
      ]
    },
    "confusionMatrix": {
      "name": "Confusion Matrix",
      "imports": ["from sklearn.metrics import confusion_matrix"],
      "code": [
        "# Make predictions using the testing set",
        "y_predict = clf.predict(X_test)",
        "cfm = confusion_matrix(y_test, y_pred)"
      ]
    }
  }
}
